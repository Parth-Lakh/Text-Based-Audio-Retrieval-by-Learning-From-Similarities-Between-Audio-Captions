clc; clear; close all;

%% STEP 1: Define Dataset (Audio + Captions)
audios = { ...
    'Cat.wav', ...
    'Rain.wav', ...
    'Campfire.wav', ...
    'Bird.wav', ...
    'Engine.wav'};

captions = { ...
    'a cat meowing', ...
    'sound of rain falling', ...
    'fire crackling sound', ...
    'birds chirping in the forest', ...
    'a car engine starting'};

numCaptions = numel(captions);

fprintf('Loaded %d audio-caption pairs.\n', numCaptions);

%% STEP 2: Load Pretrained Text Embedding Model
fprintf('\nLoading FastText word embeddings...\n');
emb = fastTextWordEmbedding;  % Built-in model

%% STEP 3: Convert Captions to Embedding Vectors
fprintf('Encoding captions...\n');
captionVecs = zeros(numCaptions, 300);  % FastText = 300-D
for i = 1:numCaptions
    words = string(split(lower(captions{i})));
    vec = word2vec(emb, words);
    captionVecs(i,:) = mean(vec, 1, 'omitnan');
end
fprintf('Caption embeddings created (%d x %d)\n', size(captionVecs,1), size(captionVecs,2));

%% STEP 4: Compute Textual Similarity Matrix (Cosine Similarity)
fprintf('\nComputing caption similarity matrix...\n');
simMatrix = captionVecs * captionVecs';
norms = vecnorm(captionVecs, 2, 2);
simMatrix = simMatrix ./ (norms * norms');
figure;
heatmap(simMatrix, 'Colormap', parula, 'Title', 'Caption Similarity Matrix');
xlabel('Captions'); ylabel('Captions');

%% ------------------------------------------------------------
% STEP 5: Convert Similarity to Non-Binary Relevance
% ------------------------------------------------------------
% Using logistic function from the IEEE paper:
% g(x_i, y_j) = 1 / (1 + exp(2.73 - 4.58 * h(x_i, x_j)))

fprintf('\nApplying logistic transformation to compute relevance...\n');
relevanceMatrix = 1 ./ (1 + exp(2.73 - 4.58 .* simMatrix));

figure;
heatmap(relevanceMatrix, 'Colormap', hot, 'Title', 'Non-Binary Audio-Caption Relevance');
xlabel('Captions'); ylabel('Captions');

%% STEP 6: Perform Retrieval Based on a Text Query (Fixed)
query = input('\nEnter a text query (e.g. "rain sounds"): ', 's');

% Encode query correctly
queryWords = string(split(lower(query)));
queryVec = word2vec(emb, queryWords);
queryVec = mean(queryVec, 1, 'omitnan');

% Compute cosine similarity between query and each caption
simQuery = (captionVecs * queryVec') ./ (vecnorm(captionVecs,2,2) * norm(queryVec));

% Sort by similarity
[sortedSim, idx] = sort(simQuery, 'descend');

fprintf('\nTop Audio Matches for Query: "%s"\n', query);
fprintf('-------------------------------------------\n');
for i = 1:numCaptions
    fprintf('%d. %-20s | %.3f | Caption: "%s"\n', i, audios{idx(i)}, sortedSim(i), captions{idx(i)});
end


%% ------------------------------------------------------------
% STEP 7 (Optional): Play the Top Ranked Audio
% ------------------------------------------------------------

choice = input('\nPlay the top-ranked audio? (y/n): ', 's');
if lower(choice) == 'y'
    [y, fs] = audioread(audios{idx(1)});
    fprintf('Playing: %s\n', audios{idx(1)});
    sound(y, fs);
end

%% ------------------------------------------------------------
% END OF SCRIPT
% ------------------------------------------------------------
